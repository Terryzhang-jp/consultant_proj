#!/usr/bin/env python3
"""
æ•°æ®ç»“æ„åˆ†æè„šæœ¬
ç”¨äºæ£€æŸ¥dataæ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ•°æ®æ–‡ä»¶çš„åˆ—åã€æ•°æ®ç±»å‹ã€å½¢çŠ¶ç­‰ä¿¡æ¯
"""

import pandas as pd
import numpy as np
import os
import json
from datetime import datetime

def analyze_csv_file(file_path):
    """åˆ†æCSVæ–‡ä»¶"""
    try:
        # å°è¯•ä¸åŒçš„ç¼–ç 
        encodings = ['utf-8', 'shift_jis', 'cp932', 'gbk', 'latin1']
        df = None
        used_encoding = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                used_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            return {"error": "æ— æ³•è¯»å–æ–‡ä»¶ - ç¼–ç é—®é¢˜"}
        
        # åŸºæœ¬ä¿¡æ¯
        info = {
            "file_type": "CSV",
            "encoding": used_encoding,
            "shape": list(df.shape),
            "columns": list(df.columns),
            "column_count": len(df.columns),
            "row_count": len(df),
            "memory_usage_mb": round(df.memory_usage(deep=True).sum() / 1024 / 1024, 2)
        }
        
        # åˆ—çš„æ•°æ®ç±»å‹
        dtypes = {}
        for col in df.columns:
            dtypes[col] = str(df[col].dtype)
        info["column_dtypes"] = dtypes
        
        # ç¼ºå¤±å€¼ç»Ÿè®¡
        missing_values = {}
        for col in df.columns:
            missing_count = df[col].isnull().sum()
            missing_pct = round(missing_count / len(df) * 100, 2)
            missing_values[col] = {
                "missing_count": int(missing_count),
                "missing_percentage": missing_pct
            }
        info["missing_values"] = missing_values
        
        # æ•°å€¼åˆ—çš„åŸºæœ¬ç»Ÿè®¡
        numeric_stats = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            try:
                stats = df[col].describe()
                numeric_stats[col] = {
                    "min": float(stats['min']) if not pd.isna(stats['min']) else None,
                    "max": float(stats['max']) if not pd.isna(stats['max']) else None,
                    "mean": float(stats['mean']) if not pd.isna(stats['mean']) else None,
                    "std": float(stats['std']) if not pd.isna(stats['std']) else None,
                    "unique_count": int(df[col].nunique())
                }
            except:
                numeric_stats[col] = {"error": "ç»Ÿè®¡è®¡ç®—å¤±è´¥"}
        info["numeric_statistics"] = numeric_stats
        
        # æ–‡æœ¬åˆ—çš„åŸºæœ¬ä¿¡æ¯
        text_stats = {}
        text_cols = df.select_dtypes(include=['object']).columns
        for col in text_cols:
            try:
                unique_count = df[col].nunique()
                sample_values = df[col].dropna().head(5).tolist()
                text_stats[col] = {
                    "unique_count": int(unique_count),
                    "sample_values": sample_values
                }
            except:
                text_stats[col] = {"error": "ç»Ÿè®¡è®¡ç®—å¤±è´¥"}
        info["text_statistics"] = text_stats
        
        # å‰5è¡Œæ•°æ®æ ·æœ¬
        try:
            sample_data = df.head(5).to_dict('records')
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            for record in sample_data:
                for key, value in record.items():
                    if pd.isna(value):
                        record[key] = None
                    elif isinstance(value, (np.integer, np.floating)):
                        record[key] = float(value) if isinstance(value, np.floating) else int(value)
                    elif isinstance(value, np.bool_):
                        record[key] = bool(value)
            info["sample_data"] = sample_data
        except:
            info["sample_data"] = "æ— æ³•è·å–æ ·æœ¬æ•°æ®"
        
        return info
        
    except Exception as e:
        return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}

def analyze_excel_file(file_path):
    """åˆ†æExcelæ–‡ä»¶"""
    try:
        # è·å–æ‰€æœ‰sheetåç§°
        excel_file = pd.ExcelFile(file_path)
        sheet_names = excel_file.sheet_names
        
        info = {
            "file_type": "Excel",
            "sheet_names": sheet_names,
            "sheet_count": len(sheet_names),
            "sheets_info": {}
        }
        
        # åˆ†ææ¯ä¸ªsheet
        for sheet_name in sheet_names:
            try:
                df = pd.read_excel(file_path, sheet_name=sheet_name)
                
                sheet_info = {
                    "shape": list(df.shape),
                    "columns": list(df.columns),
                    "column_count": len(df.columns),
                    "row_count": len(df)
                }
                
                # åˆ—çš„æ•°æ®ç±»å‹
                dtypes = {}
                for col in df.columns:
                    dtypes[col] = str(df[col].dtype)
                sheet_info["column_dtypes"] = dtypes
                
                # ç¼ºå¤±å€¼ç»Ÿè®¡
                missing_values = {}
                for col in df.columns:
                    missing_count = df[col].isnull().sum()
                    missing_pct = round(missing_count / len(df) * 100, 2)
                    missing_values[col] = {
                        "missing_count": int(missing_count),
                        "missing_percentage": missing_pct
                    }
                sheet_info["missing_values"] = missing_values
                
                # å‰3è¡Œæ•°æ®æ ·æœ¬
                try:
                    sample_data = df.head(3).to_dict('records')
                    # è½¬æ¢numpyç±»å‹
                    for record in sample_data:
                        for key, value in record.items():
                            if pd.isna(value):
                                record[key] = None
                            elif isinstance(value, (np.integer, np.floating)):
                                record[key] = float(value) if isinstance(value, np.floating) else int(value)
                            elif isinstance(value, np.bool_):
                                record[key] = bool(value)
                    sheet_info["sample_data"] = sample_data
                except:
                    sheet_info["sample_data"] = "æ— æ³•è·å–æ ·æœ¬æ•°æ®"
                
                info["sheets_info"][sheet_name] = sheet_info
                
            except Exception as e:
                info["sheets_info"][sheet_name] = {"error": f"åˆ†æå¤±è´¥: {str(e)}"}
        
        return info
        
    except Exception as e:
        return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}

def analyze_data_directory(data_dir="data"):
    """åˆ†ædataç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
    if not os.path.exists(data_dir):
        return {"error": f"ç›®å½•ä¸å­˜åœ¨: {data_dir}"}
    
    analysis_results = {
        "analysis_timestamp": datetime.now().isoformat(),
        "data_directory": data_dir,
        "files_analyzed": {},
        "summary": {
            "total_files": 0,
            "csv_files": 0,
            "excel_files": 0,
            "other_files": 0,
            "failed_files": 0
        }
    }
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    files = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]
    analysis_results["summary"]["total_files"] = len(files)
    
    print(f"ğŸ” å¼€å§‹åˆ†æ {data_dir} ç›®å½•ä¸­çš„ {len(files)} ä¸ªæ–‡ä»¶...")
    
    for file_name in files:
        file_path = os.path.join(data_dir, file_name)
        print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {file_name}")
        
        try:
            if file_name.endswith('.csv'):
                analysis_results["summary"]["csv_files"] += 1
                result = analyze_csv_file(file_path)
            elif file_name.endswith(('.xlsx', '.xls')):
                analysis_results["summary"]["excel_files"] += 1
                result = analyze_excel_file(file_path)
            else:
                analysis_results["summary"]["other_files"] += 1
                result = {"file_type": "å…¶ä»–", "note": "è·³è¿‡åˆ†æ"}
            
            if "error" in result:
                analysis_results["summary"]["failed_files"] += 1
                print(f"   âŒ åˆ†æå¤±è´¥: {result['error']}")
            else:
                print(f"   âœ… åˆ†æå®Œæˆ: {result.get('shape', 'N/A')} å½¢çŠ¶")
            
            analysis_results["files_analyzed"][file_name] = result
            
        except Exception as e:
            analysis_results["summary"]["failed_files"] += 1
            analysis_results["files_analyzed"][file_name] = {"error": f"æœªçŸ¥é”™è¯¯: {str(e)}"}
            print(f"   âŒ åˆ†æå¤±è´¥: {str(e)}")
    
    return analysis_results

def save_analysis_results(results, output_file="data_structure_analysis.json"):
    """ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
        return False

def print_summary(results):
    """æ‰“å°åˆ†ææ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®ç»“æ„åˆ†ææ‘˜è¦")
    print("="*60)
    
    summary = results.get("summary", {})
    print(f"æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}")
    print(f"CSVæ–‡ä»¶: {summary.get('csv_files', 0)}")
    print(f"Excelæ–‡ä»¶: {summary.get('excel_files', 0)}")
    print(f"å…¶ä»–æ–‡ä»¶: {summary.get('other_files', 0)}")
    print(f"åˆ†æå¤±è´¥: {summary.get('failed_files', 0)}")
    
    print("\nğŸ“‹ æ–‡ä»¶è¯¦æƒ…:")
    for file_name, file_info in results.get("files_analyzed", {}).items():
        if "error" in file_info:
            print(f"  âŒ {file_name}: {file_info['error']}")
        else:
            shape = file_info.get("shape", "N/A")
            file_type = file_info.get("file_type", "æœªçŸ¥")
            print(f"  âœ… {file_name}: {file_type}, å½¢çŠ¶: {shape}")
            
            # æ˜¾ç¤ºåˆ—å
            if "columns" in file_info:
                columns = file_info["columns"]
                print(f"     åˆ—æ•°: {len(columns)}")
                print(f"     åˆ—å: {', '.join(columns[:10])}{'...' if len(columns) > 10 else ''}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ•°æ®ç»“æ„åˆ†æ...")
    
    # åˆ†ædataç›®å½•
    results = analyze_data_directory("data")
    
    # ä¿å­˜ç»“æœ
    save_analysis_results(results)
    
    # æ‰“å°æ‘˜è¦
    print_summary(results)
    
    print("\nğŸ¯ åˆ†æå®Œæˆï¼")
    print("è¯·å°† data_structure_analysis.json æ–‡ä»¶å†…å®¹å‘é€ç»™å¼€å‘è€…è¿›è¡Œæ•°æ®ç»“æ„é€‚é…ã€‚")

if __name__ == "__main__":
    main()
