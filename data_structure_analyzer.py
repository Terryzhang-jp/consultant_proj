#!/usr/bin/env python3
"""
æ•°æ®ç»“æ„åˆ†æè„šæœ¬
ç”¨äºæ£€æŸ¥dataæ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ•°æ®æ–‡ä»¶çš„åˆ—åã€æ•°æ®ç±»å‹ã€å½¢çŠ¶ç­‰ä¿¡æ¯
"""

import pandas as pd
import numpy as np
import os
import json
from datetime import datetime

def analyze_csv_file(file_path):
    """åˆ†æCSVæ–‡ä»¶"""
    try:
        # å°è¯•ä¸åŒçš„ç¼–ç 
        encodings = ['utf-8', 'shift_jis', 'cp932', 'gbk', 'latin1']
        df = None
        used_encoding = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                used_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            return {"error": "æ— æ³•è¯»å–æ–‡ä»¶ - ç¼–ç é—®é¢˜"}
        
        # åŸºæœ¬ä¿¡æ¯
        info = {
            "file_type": "CSV",
            "encoding": used_encoding,
            "shape": list(df.shape),
            "columns": list(df.columns),
            "column_count": len(df.columns),
            "row_count": len(df)
        }

        # åˆ—çš„æ•°æ®ç±»å‹ï¼ˆåªä¿ç•™å…³é”®ä¿¡æ¯ï¼‰
        dtypes = {}
        for col in df.columns:
            dtypes[col] = str(df[col].dtype)
        info["column_dtypes"] = dtypes

        # åªç»Ÿè®¡ç¼ºå¤±å€¼æ¯”ä¾‹ï¼Œä¸è¯¦ç»†ç»Ÿè®¡
        missing_summary = {}
        for col in df.columns:
            missing_pct = round(df[col].isnull().sum() / len(df) * 100, 2)
            if missing_pct > 0:  # åªè®°å½•æœ‰ç¼ºå¤±å€¼çš„åˆ—
                missing_summary[col] = missing_pct
        info["missing_percentage"] = missing_summary

        # åªä¿ç•™å‰2è¡Œæ ·æœ¬æ•°æ®
        try:
            sample_data = df.head(2).to_dict('records')
            # ç®€åŒ–æ•°æ®è½¬æ¢
            for record in sample_data:
                for key, value in record.items():
                    if pd.isna(value):
                        record[key] = None
                    elif isinstance(value, (np.integer, np.floating)):
                        record[key] = float(value) if isinstance(value, np.floating) else int(value)
            info["sample_data"] = sample_data
        except:
            info["sample_data"] = "æ— æ³•è·å–æ ·æœ¬æ•°æ®"
        
        return info
        
    except Exception as e:
        return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}

def analyze_excel_file(file_path):
    """åˆ†æExcelæ–‡ä»¶"""
    try:
        # è·å–æ‰€æœ‰sheetåç§°
        excel_file = pd.ExcelFile(file_path)
        sheet_names = excel_file.sheet_names
        
        info = {
            "file_type": "Excel",
            "sheet_names": sheet_names,
            "sheet_count": len(sheet_names),
            "sheets_info": {}
        }
        
        # åˆ†ææ¯ä¸ªsheet
        for sheet_name in sheet_names:
            try:
                df = pd.read_excel(file_path, sheet_name=sheet_name)
                
                sheet_info = {
                    "shape": list(df.shape),
                    "columns": list(df.columns),
                    "column_count": len(df.columns),
                    "row_count": len(df)
                }

                # åˆ—çš„æ•°æ®ç±»å‹
                dtypes = {}
                for col in df.columns:
                    dtypes[col] = str(df[col].dtype)
                sheet_info["column_dtypes"] = dtypes

                # åªç»Ÿè®¡æœ‰ç¼ºå¤±å€¼çš„åˆ—
                missing_summary = {}
                for col in df.columns:
                    missing_pct = round(df[col].isnull().sum() / len(df) * 100, 2)
                    if missing_pct > 0:
                        missing_summary[col] = missing_pct
                sheet_info["missing_percentage"] = missing_summary

                # åªä¿ç•™å‰2è¡Œæ ·æœ¬æ•°æ®
                try:
                    sample_data = df.head(2).to_dict('records')
                    # ç®€åŒ–æ•°æ®è½¬æ¢
                    for record in sample_data:
                        for key, value in record.items():
                            if pd.isna(value):
                                record[key] = None
                            elif isinstance(value, (np.integer, np.floating)):
                                record[key] = float(value) if isinstance(value, np.floating) else int(value)
                    sheet_info["sample_data"] = sample_data
                except:
                    sheet_info["sample_data"] = "æ— æ³•è·å–æ ·æœ¬æ•°æ®"
                
                info["sheets_info"][sheet_name] = sheet_info
                
            except Exception as e:
                info["sheets_info"][sheet_name] = {"error": f"åˆ†æå¤±è´¥: {str(e)}"}
        
        return info
        
    except Exception as e:
        return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}

def analyze_data_directory(data_dir="data"):
    """åˆ†ædataç›®å½•ä¸­çš„å…³é”®æ–‡ä»¶"""
    if not os.path.exists(data_dir):
        return {"error": f"ç›®å½•ä¸å­˜åœ¨: {data_dir}"}

    # å®šä¹‰æˆ‘ä»¬å…³å¿ƒçš„å…³é”®æ–‡ä»¶ï¼ˆç”¨äºhypothesiséªŒè¯ï¼‰
    key_files = [
        "LPãƒ’ã‚¹ãƒˆãƒªãƒ¼_hashed.csv",
        "å ±é…¬ãƒ‡ãƒ¼ã‚¿_hashed.csv",
        "æ‡²æˆ’å‡¦åˆ†_äº‹æ•…åŒºåˆ†ç­‰è¿½åŠ _hashed.csv",
        "æ¥­ç¸¾_hashed.csv",
        "MTGå‡ºå¸­ç‡2021-2023_hashed.csv",
        "ç¤¾é•·æ¯å…¥è³å±¥æ­´_LP",  # éƒ¨åˆ†åŒ¹é…
        "è‹¦æƒ…ãƒ‡ãƒ¼ã‚¿_hashed.xlsx",
        "äº‹å‹™ãƒŸã‚¹ãƒ‡ãƒ¼ã‚¿"  # éƒ¨åˆ†åŒ¹é…
    ]

    analysis_results = {
        "analysis_timestamp": datetime.now().isoformat(),
        "data_directory": data_dir,
        "files_analyzed": {},
        "summary": {
            "total_files": 0,
            "csv_files": 0,
            "excel_files": 0,
            "other_files": 0,
            "failed_files": 0
        }
    }

    # è·å–æ‰€æœ‰æ–‡ä»¶
    all_files = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]

    # è¿‡æ»¤å‡ºå…³é”®æ–‡ä»¶
    files = []
    for file_name in all_files:
        for key_file in key_files:
            if key_file in file_name:
                files.append(file_name)
                break

    analysis_results["summary"]["total_files"] = len(files)
    analysis_results["summary"]["total_files_in_directory"] = len(all_files)
    
    print(f"ğŸ” å¼€å§‹åˆ†æ {data_dir} ç›®å½•ä¸­çš„ {len(files)} ä¸ªå…³é”®æ–‡ä»¶ (æ€»å…±{len(all_files)}ä¸ªæ–‡ä»¶)...")

    for file_name in files:
        file_path = os.path.join(data_dir, file_name)
        print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {file_name}")
        
        try:
            if file_name.endswith('.csv'):
                analysis_results["summary"]["csv_files"] += 1
                result = analyze_csv_file(file_path)
            elif file_name.endswith(('.xlsx', '.xls')):
                analysis_results["summary"]["excel_files"] += 1
                result = analyze_excel_file(file_path)
            else:
                analysis_results["summary"]["other_files"] += 1
                result = {"file_type": "å…¶ä»–", "note": "è·³è¿‡åˆ†æ"}
            
            if "error" in result:
                analysis_results["summary"]["failed_files"] += 1
                print(f"   âŒ åˆ†æå¤±è´¥: {result['error']}")
            else:
                print(f"   âœ… åˆ†æå®Œæˆ: {result.get('shape', 'N/A')} å½¢çŠ¶")
            
            analysis_results["files_analyzed"][file_name] = result
            
        except Exception as e:
            analysis_results["summary"]["failed_files"] += 1
            analysis_results["files_analyzed"][file_name] = {"error": f"æœªçŸ¥é”™è¯¯: {str(e)}"}
            print(f"   âŒ åˆ†æå¤±è´¥: {str(e)}")
    
    return analysis_results

def save_analysis_results(results, output_file="data_structure_analysis.json"):
    """ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
        return False

def print_summary(results):
    """æ‰“å°åˆ†ææ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®ç»“æ„åˆ†ææ‘˜è¦")
    print("="*60)
    
    summary = results.get("summary", {})
    print(f"æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}")
    print(f"CSVæ–‡ä»¶: {summary.get('csv_files', 0)}")
    print(f"Excelæ–‡ä»¶: {summary.get('excel_files', 0)}")
    print(f"å…¶ä»–æ–‡ä»¶: {summary.get('other_files', 0)}")
    print(f"åˆ†æå¤±è´¥: {summary.get('failed_files', 0)}")
    
    print("\nğŸ“‹ æ–‡ä»¶è¯¦æƒ…:")
    for file_name, file_info in results.get("files_analyzed", {}).items():
        if "error" in file_info:
            print(f"  âŒ {file_name}: {file_info['error']}")
        else:
            shape = file_info.get("shape", "N/A")
            file_type = file_info.get("file_type", "æœªçŸ¥")
            print(f"  âœ… {file_name}: {file_type}, å½¢çŠ¶: {shape}")
            
            # æ˜¾ç¤ºåˆ—å
            if "columns" in file_info:
                columns = file_info["columns"]
                print(f"     åˆ—æ•°: {len(columns)}")
                print(f"     åˆ—å: {', '.join(columns[:10])}{'...' if len(columns) > 10 else ''}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ•°æ®ç»“æ„åˆ†æ...")
    
    # åˆ†ædataç›®å½•
    results = analyze_data_directory("data")
    
    # ä¿å­˜ç»“æœ
    save_analysis_results(results)
    
    # æ‰“å°æ‘˜è¦
    print_summary(results)
    
    print("\nğŸ¯ åˆ†æå®Œæˆï¼")
    print("è¯·å°† data_structure_analysis.json æ–‡ä»¶å†…å®¹å‘é€ç»™å¼€å‘è€…è¿›è¡Œæ•°æ®ç»“æ„é€‚é…ã€‚")

if __name__ == "__main__":
    main()
